Answers:

--- Part 1d:

Flesch-Kincaid (FK) Grade Level serves as an effective tool for determining fundamental readability that was widely used for 19th and 20th century novels, and it often underestimates the real complexity behind literary writings and disregards metaphorical language, narrative structure and readers interpretation. For instance, Dorian Grey with a low score of 4.95 indicates the novel is appropriate for elementary school readers. On the other hand, the novel dives into complicated topics such as vanity, corruption and the conflict of human nature, which demand for a broader knowledge of thinking and mature understanding of the cultural background. Therefore, the FK score is not reliable as it only assesses superficial characteristics, such as number of syllables used but not the depth of thought or difficulty of interpretation.

Conversely, some novels are classified as very challenging by FK because of their lengthy sentences and advanced vocabulary, despite the topics not being excessively complicated. Considering their complex language constructions, Erewhon and Golden Bowl scores higher because the concepts expressed in these novels are often understandable with some background knowledge. Consequently, FK scores do not accurately reflect text difficulty when the difficulty comes from themes and structures, rather than words and sentences.


--- Part 2f:

In order to complete this task, I have used a custom tokenizer to clean and standardise the speech texts before the vectorization, in order to increase classification performance. In the beginning, the tokenizer will convert all of the text to lowercase and then use standard expressions to remove any characters that are not letters. The cleaned text is then tokenized using NLTK by filtering out English stopwords and removing any extreme short tokens. As a result, lemmatization is applied. In this context, lemmatization was used instead of stemming because it preserves the semantically and syntactically accurate base forms of words. On the other hand, stemming often generates simplified or non-standard forms, thus lemmatization maintains the grammatical nature of words, as this is a significant factor in formal contexts such as political speech. The impact of this tokenizer was seen in the best performance of the linear SVC model, which had the best F1 score of 0.66 and accuracy of 0.77 with parameters C=100. Hence, this classifier showed a balanced performance across political categories, suggesting that the lemmatised features have effectively captured class-specific linguistic patterns. In contrast, the Random Forest approach with 400 estimators had the best efficiency with a total runtime of 51.7 seconds, but severely underperformed in classification, resulting in an F1 score of 0.43 and accuracy of 0.72. Based on these findings, it seems that the custom tokenizer proved to be useful for SVM linear classifiers, which are highly dependent on features that both clean and contextually relevant in high-dimensional space.