{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e370ad",
   "metadata": {},
   "source": [
    "## Part a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df54be3",
   "metadata": {},
   "source": [
    "Read the hansard40000.csv dataset in the texts directory into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b0c063da",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = Path().cwd()\n",
    "part_two_data_path = root_directory / \"data/hansard40000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263a6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8084, 8)\n",
      "                                                speech  \\\n",
      "63   It has been less than two weeks since the Gove...   \n",
      "99   I am delighted to announce that last Friday we...   \n",
      "100  I thank the Secretary of State for advance sig...   \n",
      "101  After the right hon. Lady’s congratulations to...   \n",
      "104  I congratulate the Secretary of State. I recog...   \n",
      "\n",
      "                       party                  constituency        date  \\\n",
      "63              Conservative               Suffolk Coastal  2020-09-14   \n",
      "99              Conservative            South West Norfolk  2020-09-14   \n",
      "100                   Labour  Islington South and Finsbury  2020-09-14   \n",
      "101             Conservative            South West Norfolk  2020-09-14   \n",
      "104  Scottish National Party                   Dundee East  2020-09-14   \n",
      "\n",
      "    speech_class               major_heading  year       speakername  \n",
      "63        Speech           Work and Pensions  2020    Therese Coffey  \n",
      "99        Speech  Japan Free Trade Agreement  2020   Elizabeth Truss  \n",
      "100       Speech  Japan Free Trade Agreement  2020  Emily Thornberry  \n",
      "101       Speech  Japan Free Trade Agreement  2020   Elizabeth Truss  \n",
      "104       Speech  Japan Free Trade Agreement  2020     Stewart Hosie  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(part_two_data_path)\n",
    "\n",
    "# rename the ‘Labour (Co-op)’ value in ‘party’ column to ‘Labour’,\n",
    "df[\"party\"] = df[\"party\"].replace(\"Labour (Co-op)\", \"Labour\")\n",
    "\n",
    "# remove any rows where the value of the ‘party’ column is not one of the\n",
    "# four most common party names, and remove the ‘Speaker’ value\n",
    "party_name_count = df[\"party\"].value_counts()\n",
    "if \"Speaker\" in party_name_count:\n",
    "    party_name_count = party_name_count.drop(\"Speaker\")\n",
    "\n",
    "most_common_party_name = party_name_count.nlargest(4).index\n",
    "df = df[df[\"party\"].isin(most_common_party_name)]\n",
    "\n",
    "# remove any rows where the value in the ‘speech_class’ column is not\n",
    "# ‘Speech’\n",
    "df = df[df[\"speech_class\"] == \"Speech\"]\n",
    "\n",
    "# remove any rows where the text in the ‘speech’ column is less than 1000\n",
    "# characters long.\n",
    "df = df[df[\"speech\"].str.len() >= 1000]\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27443cee",
   "metadata": {},
   "source": [
    "## Part b:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eeebb4",
   "metadata": {},
   "source": [
    "Vectorise the speeches using TfidfVectorizer from scikit-learn. Use the default 5\n",
    "parameters, except for omitting English stopwords and setting max_features to\n",
    "3000. Split the data into a train and test set, using stratified sampling, with a\n",
    "random seed of 26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4a5b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorise the speeches using TfidfVectorizer from scikit-learn.\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features= 3000)\n",
    "X = vectorizer.fit_transform(df[\"speech\"])\n",
    "y = df[\"party\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=26)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31836310",
   "metadata": {},
   "source": [
    "## Part c:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b40f7",
   "metadata": {},
   "source": [
    "Train RandomForest (with n_estimators=300) and SVM with linear kernel classifiers on the training set, and print the scikit-learn macro-average f1 score and\n",
    "classification report for each classifier on the test set. The label that you are\n",
    "trying to predict is the ‘party’ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50913ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.47296725014116325\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.73      0.96      0.83       964\n",
      "                 Labour       0.75      0.48      0.58       463\n",
      "       Liberal Democrat       0.00      0.00      0.00        54\n",
      "Scottish National Party       0.85      0.33      0.48       136\n",
      "\n",
      "               accuracy                           0.74      1617\n",
      "              macro avg       0.58      0.44      0.47      1617\n",
      "           weighted avg       0.72      0.74      0.70      1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcolecu/.pyenv/versions/3.10.4/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcolecu/.pyenv/versions/3.10.4/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcolecu/.pyenv/versions/3.10.4/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=300, random_state=26)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest_prediction = random_forest.predict(X_test)\n",
    "print(\"Macro F1 Score:\" ,f1_score(y_test, random_forest_prediction, average=\"macro\"))\n",
    "print(classification_report(y_test, random_forest_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0339905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.5933446121140653\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.83      0.92      0.87       964\n",
      "                 Labour       0.74      0.71      0.72       463\n",
      "       Liberal Democrat       1.00      0.07      0.14        54\n",
      "Scottish National Party       0.78      0.54      0.64       136\n",
      "\n",
      "               accuracy                           0.80      1617\n",
      "              macro avg       0.84      0.56      0.59      1617\n",
      "           weighted avg       0.81      0.80      0.79      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM with Linear Classifier\n",
    "SVM_Linear = SVC(kernel = \"linear\", random_state=26)\n",
    "SVM_Linear.fit(X_train, y_train)\n",
    "SVM_Linear_prediction = SVM_Linear.predict(X_test)\n",
    "print(\"Macro F1 Score:\" ,f1_score(y_test, SVM_Linear_prediction, average=\"macro\"))\n",
    "print(classification_report(y_test, SVM_Linear_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079a7db5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe01a7",
   "metadata": {},
   "source": [
    "## Part d:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b3760",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Adjust the parameters of the Tfidfvectorizer so that unigrams, bi-grams and 5\n",
    "tri-grams will be considered as features, limiting the total number of features to\n",
    "3000. Print the classification report as in 2(c) again using these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b42f82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorise the speeches\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features= 3000, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(df[\"speech\"])\n",
    "y = df[\"party\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10952d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.73      0.96      0.83       964\n",
      "                 Labour       0.75      0.48      0.58       463\n",
      "       Liberal Democrat       0.00      0.00      0.00        54\n",
      "Scottish National Party       0.85      0.33      0.48       136\n",
      "\n",
      "               accuracy                           0.74      1617\n",
      "              macro avg       0.58      0.44      0.47      1617\n",
      "           weighted avg       0.72      0.74      0.70      1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcolecu/.pyenv/versions/3.10.4/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcolecu/.pyenv/versions/3.10.4/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcolecu/.pyenv/versions/3.10.4/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=300, random_state=26)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest_prediction = random_forest.predict(X_test)\n",
    "print(classification_report(y_test, random_forest_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "962a1c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.84      0.92      0.88       964\n",
      "                 Labour       0.75      0.73      0.74       463\n",
      "       Liberal Democrat       1.00      0.04      0.07        54\n",
      "Scottish National Party       0.78      0.56      0.65       136\n",
      "\n",
      "               accuracy                           0.81      1617\n",
      "              macro avg       0.84      0.56      0.59      1617\n",
      "           weighted avg       0.81      0.81      0.79      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM with Linear Classifier\n",
    "SVM_Linear = SVC(kernel = \"linear\", random_state=26)\n",
    "SVM_Linear.fit(X_train, y_train)\n",
    "SVM_Linear_prediction = SVM_Linear.predict(X_test)\n",
    "print(classification_report(y_test, SVM_Linear_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7cb287",
   "metadata": {},
   "source": [
    "## Part e: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f176328e",
   "metadata": {},
   "source": [
    "Implement a new custom tokenizer and pass it to the tokenizer argument of\n",
    "Tfidfvectorizer. You can use this function in any way you like to try to achieve\n",
    "the best classification performance while keeping the number of features to no\n",
    "more than 3000, and using the same three classifiers as above. Print the classification report for the best performing classifier using your tokenizer. Marks\n",
    "will be awarded both for a high overall classification performance, and a good\n",
    "trade-off between classification performance and efficiency (i.e., using fewer parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b3a271a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/marcolecu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/marcolecu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/marcolecu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def new_custom_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    word_tokens = word_tokenize(text)\n",
    "\n",
    "    cleaned_word_tokens = []\n",
    "    for token in word_tokens:\n",
    "        if token.isalpha() and token.islower() and token not in stop_words:\n",
    "            lemma_token = lemmatizer.lemmatize(token)\n",
    "            if len(lemma_token) > 2:\n",
    "                cleaned_word_tokens.append(lemma_token)\n",
    "\n",
    "    return cleaned_word_tokens \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c1ac07e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcolecu/.pyenv/versions/3.10.4/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_vectorizer = TfidfVectorizer(tokenizer = new_custom_tokenizer, max_features=3000)\n",
    "X = new_vectorizer.fit_transform(df[\"speech\"])\n",
    "y = df[\"party\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=26)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_evaluation(model_class, param_grid, label):\n",
    "    \"\"\" Use GridSearch Cross Validation to find highest-performing model based on f1_macro\n",
    "    \n",
    "    Args:\n",
    "        model_class (class): A scikit-learn compatible estimator class (not an instance).\n",
    "        param_grid (dict): Dictionary with parameters names (str) as keys and lists of parameter settings to try.\n",
    "        label (str): A label to identify the model in the results.\n",
    "\n",
    "    Returns:\n",
    "        dict: metadata related the model\n",
    "    \n",
    "    \"\"\"\n",
    "    classifier_grid = GridSearchCV(estimator= model_class(), param_grid= param_grid, cv=3, scoring =\"f1_macro\", n_jobs=-1)\n",
    "\n",
    "    start_training_time = time.time()\n",
    "    classifier_grid.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_training_time\n",
    "\n",
    "    best_model = classifier_grid.best_estimator_\n",
    "\n",
    "    start_prediciting_time = time.time()\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    predicicting_time = time.time() - start_prediciting_time\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average = \"macro\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"parameters\": classifier_grid.best_params_,\n",
    "        \"model\": best_model,\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        'training_time': training_time,\n",
    "        \"predicting_time\": predicicting_time,\n",
    "        \"total_time\": training_time + predicicting_time,\n",
    "        \"y_pred\": y_pred\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a503189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best performance model: SVC Linear\n",
      "Parameters: {'C': 100}\n",
      "Total time: 53.119 seconds\n",
      "\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.83      0.86      0.84       964\n",
      "                 Labour       0.67      0.69      0.68       463\n",
      "       Liberal Democrat       0.64      0.33      0.44        54\n",
      "Scottish National Party       0.73      0.62      0.67       136\n",
      "\n",
      "               accuracy                           0.77      1617\n",
      "              macro avg       0.72      0.63      0.66      1617\n",
      "           weighted avg       0.77      0.77      0.77      1617\n",
      "\n",
      "\n",
      " Best efficient model: Random Forest\n",
      "Parameters: {'max_depth': None, 'n_estimators': 400}\n",
      "Total time: 51.657 seconds\n",
      "\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.71      0.98      0.82       964\n",
      "                 Labour       0.76      0.43      0.55       463\n",
      "       Liberal Democrat       0.00      0.00      0.00        54\n",
      "Scottish National Party       0.88      0.21      0.34       136\n",
      "\n",
      "               accuracy                           0.72      1617\n",
      "              macro avg       0.59      0.41      0.43      1617\n",
      "           weighted avg       0.72      0.72      0.68      1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcolecu/.pyenv/versions/3.10.4/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcolecu/.pyenv/versions/3.10.4/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcolecu/.pyenv/versions/3.10.4/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_forest_parameter_grid = {\"n_estimators\": [50, 100, 200, 300, 400, 500],\n",
    "                                \"max_depth\": [None, 10, 20, 30]}\n",
    "\n",
    "svc_parameter_grid = {\"C\": [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "random_forest_result = grid_search_evaluation(lambda: RandomForestClassifier(random_state=26), random_forest_parameter_grid, \"Random Forest\")\n",
    "svc_linear_result = grid_search_evaluation(lambda: SVC(kernel=\"linear\", random_state=26), svc_parameter_grid, \"SVC Linear\")\n",
    "\n",
    "results = [random_forest_result, svc_linear_result]\n",
    "\n",
    "best_performance = max(results, key=lambda x: x['f1'])\n",
    "best_efficiency = min(results, key=lambda x: x[\"total_time\"])\n",
    "\n",
    "# Best by performance\n",
    "print(f\"\\n Best performance model: {best_performance['label']}\")\n",
    "print(f\"Parameters: {best_performance['parameters']}\")\n",
    "print(f\"Total time: {best_performance['total_time']:.3f} seconds\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, best_performance['y_pred']))\n",
    "print(\"---\")\n",
    "# Best by effiency\n",
    "if best_efficiency != best_performance:\n",
    "    print(f\"\\n Best efficient model: {best_efficiency['label']}\")\n",
    "print(f\"Parameters: {best_efficiency['parameters']}\")\n",
    "print(f\"Total time: {best_efficiency['total_time']:.3f} seconds\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, best_efficiency['y_pred']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b53ffd",
   "metadata": {},
   "source": [
    "## Part f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f375c49",
   "metadata": {},
   "source": [
    "# Explain your tokenizer function and discuss its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae4e4c",
   "metadata": {},
   "source": [
    "In order to complete this task, I have used a custom tokenizer to clean and standardise the speech texts before the vectorization, in order to increase classification performance. In the beginning, the tokenizer will convert all of the text to lowercase and then use standard expressions to remove any characters that are not letters. The cleaned text is then tokenized using NLTK by filtering out English stopwords and removing any extreme short tokens. As a result, lemmatization is applied. In this context, lemmatization was used instead of stemming because it preserves the semantically and syntactically accurate base forms of words. On the other hand, stemming often generates simplified or non-standard forms, thus lemmatization maintains the grammatical nature of words, as this is a significant factor in formal contexts such as political speech. The impact of this tokenizer was seen in the best performance of the linear SVC model, which had the best F1 score of 0.66 and accuracy of 0.77 with parameters C=100. Hence, this classifier showed a balanced performance across political categories, suggesting that the lemmatised features have effectively captured class-specific linguistic patterns. In contrast, the Random Forest approach with 400 estimators had the best efficiency with a total runtime of 51.7 seconds, but severely underperformed in classification, resulting in an F1 score of 0.43 and accuracy of 0.72. Based on these findings, it seems that the custom tokenizer proved to be useful for SVM linear classifiers, which are highly dependent on features that both clean and contextually relevant in high-dimensional space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
